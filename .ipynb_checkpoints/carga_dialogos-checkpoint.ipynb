{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neo4j_connector as nc\n",
    "import re\n",
    "import docx\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tag import StanfordPOSTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "import pickle\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dialogs(doc):\n",
    "    inicio = False\n",
    "    dialog = ''\n",
    "    dialogs = []\n",
    "    for par in doc.paragraphs:   \n",
    "        if par.text == '###':\n",
    "            inicio = True\n",
    "        else:\n",
    "            inicio = False\n",
    "\n",
    "        if inicio:\n",
    "            if dialog == '':\n",
    "                pass\n",
    "            else:\n",
    "                dialogs.append(dialog)\n",
    "            dialog = ''\n",
    "        else:\n",
    "            dialog = dialog + par.text + ' '\n",
    "    return dialogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_dialogs(dialogs):\n",
    "    output = []\n",
    "    for dialog in dialogs:\n",
    "        pos_fin = dialog.find(':')\n",
    "        output.append([dialog[:pos_fin].lower(), dialog[pos_fin + 1 :].lower()])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_parenthesis(text):\n",
    "    regex = r\" \\(([^\\)]+)\\)\"\n",
    "    matches = re.finditer(regex, text)\n",
    "    output = text\n",
    "    for matchNum, match in enumerate(matches, start=1):\n",
    "        t_parentesis = match.group()\n",
    "        output = output.replace(t_parentesis, '')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aunque no te lo creas a veces no se escribe del todo correctamente\n",
    "def clean_mr_mrs(text):\n",
    "    return text.replace('el señor ', '').replace('la señora ', '') \\\n",
    ".replace('el señora', '').replace('la señor', '') \\\n",
    ".replace('señor ', '').replace('señora ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    return text.replace('?', '').replace('¿', '').replace('«', '').replace('»', '') \\\n",
    ".replace('.', ' ').replace(',', ' ').replace('—', ' ').replace('-', ' ').replace('%', ' ') \\\n",
    ".replace('š', ' ').replace(';', ' ').replace('!', ' ').replace('¡', ' ') \\\n",
    ".replace('–', ' ').replace(' : ', ': ').replace(':', ' ').replace('…', ' ').replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_names(name):\n",
    "    return name.replace('presidente del gobierno en funciones', 'sánchez pérez-castejón') \\\n",
    "        .replace('ministra de justicia en funciones', 'delgado garcía') \\\n",
    "        .replace('ministra de hacienda en funciones', 'montero cuadrado') \\\n",
    "        .replace('ministro del interior en funciones', 'grande-marlaska gómez') \\\n",
    "        .replace('rodrí guez hernández', 'rodríguez hernández') \\\n",
    "        .replace('ministro de agricultura pesca y alimentación en funciones', 'planas puchades') \\\n",
    "        .replace('ministro de fomento en funciones', 'ábalos meco') \\\n",
    "        .replace('ministra de economía y empresa en funciones', 'calviño santamaría') \\\n",
    "        .replace(' candidato a la presidencia del gobierno', '') \\\n",
    "        .replace('ministro de inclusión  seguridad social y migraciones', 'escrivá belmonte') \\\n",
    "        .replace('ministra de política territorial y función pública', 'darias san sebastián') \\\n",
    "        .replace('ministra de hacienda', 'montero cuadrado') \\\n",
    "        .replace('representante de la asamblea regional de murcia', 'conesa alcaraz') \\\n",
    "        .replace('de olano vela', 'olano vela') \\\n",
    "        .replace('ministro del interior', 'grande-marlaska gómez') \\\n",
    "        .replace('ministro de interior', 'grande-marlaska gómez') \\\n",
    "        .replace('ministro de agricultura pesca y alimentación', 'planas puchades') \\\n",
    "        .replace('ministro de transportes movilidad y agenda urbana', 'ábalos meco') \\\n",
    "        .replace('presidente del gobierno', 'sánchez pérez-castejón') \\\n",
    "        .replace('ministro de sanidad', 'illa roca') \\\n",
    "        .replace('concicao', 'garriga vaz de concicao').replace('garriga vaz de garriga vaz de', 'garriga vaz de') \\\n",
    "        .replace('oblanca', 'martínez oblanca') \\\n",
    "        .replace('ministra de igualdad', 'montero gil') \\\n",
    "        .replace('herrer', 'rodríguez herrer').replace('rodríguez rodríguez herrer', 'rodríguez herrer') \\\n",
    "        .replace('ministra de industria comercio y turismo', 'maroto illera') \\\n",
    "        .replace('ministro de inclusión seguridad social y migraciones', 'escrivá belmonte') \\\n",
    "        .replace(' moro', 'oramas gonzález-moro') \\\n",
    "        .replace('ministra de asuntos exteriores unión europea y cooperación', 'gonzález laya') \\\n",
    "        .replace('ministro de justicia', 'campo moreno') \\\n",
    "        .replace('vicepresidente segundo del gobierno y ministro de derechos sociales y agenda 2030', 'iglesias turrión') \\\n",
    "        .replace('vicepresidente segundo del gobierno y ministro de derecho sociales y agenda 2030', 'iglesias turrión') \\\n",
    "        .replace('martínez martínez oblanca', 'martínez oblanca') \\\n",
    "        .replace('sanchez', 'sánchez').replace('castejon', 'castejón') \\\n",
    "        .replace('ministro de inclusión, seguridad social y migraciones', 'escrivá belmonte') \\\n",
    "        .replace('vicepresidenta tercera del gobierno y ministra de asuntos económicos y transformación digital', 'calviño santamaría') \\\n",
    "        .replace('ministro de transportes, movilidad y agenda urbana', 'ábalos meco') \\\n",
    "        .replace('ministro de agricultura, pesca y alimentación', 'planas puchades') \\\n",
    "        .replace('vicepresidenta primera del gobierno y ministra de la presidencia relaciones con las cortes y memoria democrática', 'calvo poyato') \\\n",
    "        .replace('vicepresidenta del gobierno y ministra de la presidencia relaciones con las cortes y memoria democrática', 'calvo poyato') \\\n",
    "        .replace('vicepresidenta cuarta del gobierno y ministra para la transición ecológica y el reto demográfico', 'ribera rodríguez') \\\n",
    "        .replace('baldoví i roda', 'baldoví roda').replace('cantanyer', 'castanyer') \\\n",
    "        .replace('ministra de defensa', 'robles fernández') \\\n",
    "        .replace('ministra de trabajo y economía social', 'díaz pérez')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(dialog):\n",
    "    list_specific_stop_words = ['gracias', 'señor', 'señora', 'señorías', 'presidenta', 'ministro', 'ustedes',\n",
    "                                'usted', 'si', 'señores', 'solo', 'sólo', 'va', 'hoy', 'van', 'verdad', 'presidente', 'vamos', 'ser', 'creo',\n",
    "                               'dicho', 'día', 'decía', 'dicho', 'años', 'quiero', 'claro', 'vez', 'así', 'decir', 'poder']\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "\n",
    "    word_tokens = word_tokenize(dialog)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    filtered_sentence = [w for w in filtered_sentence if not w in list_specific_stop_words]\n",
    "        \n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dialogs(dialogs):\n",
    "    output = []\n",
    "    for dialog in dialogs:\n",
    "        speaker = clean_names(clean_mr_mrs(clean_parenthesis(dialog[0]).replace(',', '')))\n",
    "        text = remove_stopwords(clean_text(clean_parenthesis(dialog[1])))\n",
    "        output.append([speaker, text])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacenamos en una lista, la relacion y la lista de diálogos\n",
    "congreso = []\n",
    "for file in os.listdir('files/'):\n",
    "    if file[-4:] == 'docx':\n",
    "        doc = docx.Document('files/' + file) \n",
    "        dialogs = extract_dialogs(doc)\n",
    "        sep_dialogs = separate_dialogs(dialogs)\n",
    "        cl_dialogs = clean_dialogs(sep_dialogs)\n",
    "        relation = file[:-5]\n",
    "        congreso.append([relation, cl_dialogs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En este momento tenemos una estructura de este tipo:\n",
    "['ID_DEBATE', [[DIPUTADO, [PALABRAS]]]]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tagger_model(list_words, sw_generate_model):\n",
    "    jar = 'nlp/stanford-postagger.jar'\n",
    "    model = 'nlp/spanish.tagger'\n",
    "    nlp = spacy.load('es_core_news_md')\n",
    "    pos_tagger = StanfordPOSTagger(model, jar, encoding='utf8')\n",
    "    temp = list(set(list_words)) \n",
    "    max_count  = len(temp)\n",
    "    dialog = []\n",
    "    ind = 0\n",
    "    jump = 100\n",
    "    while ind < max_count:\n",
    "        dialog.append(temp[ind:ind + jump])\n",
    "        ind = ind+jump\n",
    "    \n",
    "    if sw_generate_model:\n",
    "        try:\n",
    "            os.remove('words.pickle')\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # taggeamos las palabras de 100 en 100 para no desbordar la memoria\n",
    "        pbar = tqdm(dialog)\n",
    "        for dialogs in pbar:\n",
    "            try:\n",
    "                with open('words.pickle', 'rb') as handle:\n",
    "                    words = pickle.load(handle)\n",
    "                    words.extend(pos_tagger.tag(dialogs))\n",
    "                    with open('words.pickle', 'wb') as handle:\n",
    "                        pickle.dump(words, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            except Exception as e:\n",
    "                words = pos_tagger.tag(dialogs)\n",
    "                \n",
    "                with open('words.pickle', 'wb') as handle:\n",
    "                    pickle.dump(words, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    else:\n",
    "        with open('words.pickle', 'rb') as handle:\n",
    "            words = pickle.load(handle)\n",
    "\n",
    "    output = []\n",
    "    pbar = tqdm(words)\n",
    "    for word in pbar:\n",
    "        pbar.set_description(\"Palabras procesadas\")\n",
    "        if word[0].isnumeric():\n",
    "            pass\n",
    "        else:\n",
    "            temp = nlp(word[0])[0].lemma_\n",
    "            #quito los 'rg'\n",
    "            if word[1][0:2] in ['nc', 'np', 'aq', ]:\n",
    "                if temp not in ['así', 'parte', 'puede', 'hace', 'hacer', 'diputado', 'diputados', '%', 'solo', 'hoy']:\n",
    "                    output.append(temp)\n",
    "            else:\n",
    "                if word[1][0:1] == 'v':\n",
    "                    if temp not in ['ser', 'hacer', 'ir', 'decir', 'poder', 'estar', \n",
    "                                    'llevar', 'tener', 'querer', 'ser', 'ir', 'v']:\n",
    "                        output.append(temp)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_list_words(congreso):\n",
    "    output = []\n",
    "    for el1 in congreso:\n",
    "        for el2 in el1[1]:\n",
    "            output.extend(el2[1])  \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_words = generate_list_words(congreso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r data\n",
    "data\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger_model = generate_tagger_model(list_words, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dialogs (congreso, list_words_tagged):\n",
    "    nlp = spacy.load('es_core_news_md')\n",
    "    graph = nc.generate_graph()\n",
    "    matcher = nc.generate_nodeMatcher(graph)\n",
    "    pbar1 = tqdm(congreso)\n",
    "    \n",
    "    for el1 in pbar1:       \n",
    "        pbar1.set_description(\"Documentos.....\")\n",
    "        relation = el1[0]\n",
    "        for el2 in el1[1]:\n",
    "            speaker = el2[0].strip()\n",
    "            diputado = nc.return_diputado(matcher, speaker)\n",
    "            if diputado is None:\n",
    "                print(\"PERSONA NO ENCONTRADA: \")\n",
    "                print(speaker)\n",
    "                print(relation)\n",
    "            else:\n",
    "                for word in el2[1]:\n",
    "                    if word.isnumeric():\n",
    "                        pass\n",
    "                    else:\n",
    "                        lemma = nlp(word)[0].lemma_\n",
    "                        if lemma in list_words_tagged:\n",
    "                            graph.run(nc.insert_palabra(word))\n",
    "                            graph.run(nc.insert_relation(diputado['apellidos'], word, relation))\n",
    "                        else:\n",
    "                            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dialogs(congreso, tagger_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
