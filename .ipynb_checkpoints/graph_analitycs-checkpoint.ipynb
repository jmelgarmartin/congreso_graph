{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Par√°metro para generar el modelo del taggeador\n",
    "data = True\n",
    "%store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%run ./carga_diputados.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%run ./carga_dialogos.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neo4j_connector as nc\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nc.generate_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grupos_parlamentarios = list(graph.run('MATCH (d:Diputado) RETURN DISTINCT(d.grupo) AS grupo ORDER BY grupo ASC').to_data_frame()['grupo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBTENEMOS LISTA DE RELACIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'MATCH ()-[relation]-() RETURN DISTINCT(relation.pleno) as sesion order by sesion asc'\n",
    "sesiones = graph.run(query).to_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lista_palabras(grupo, plenos):\n",
    "    query = \"MATCH (d:Diputado)-[rel]-(p:Palabra) \"\n",
    "    query = query + \"WHERE d.grupo = '\" + grupo +\"' \"\n",
    "    query = query + \"AND rel.pleno IN \" + str(plenos) + \" \"\n",
    "    query = query + \"RETURN rel.pleno as pleno, d.grupo as grupo, p.palabra as palabra, SUM(rel.veces) as veces \"\n",
    "    query = query + \"ORDER BY veces DESC, palabra ASC LIMIT 15\"\n",
    "    return graph.run(query).to_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lista_palabras_hist(grupo, plenos):\n",
    "    query = \"MATCH (d:Diputado)-[rel]-(p:Palabra) \"\n",
    "    query = query + \"WHERE d.grupo = '\" + grupo +\"' \"\n",
    "    query = query + \"AND rel.pleno IN \" + str(plenos) + \" \"\n",
    "    query = query + \"RETURN d.grupo as grupo, p.palabra as palabra, SUM(rel.veces) as veces \"\n",
    "    query = query + \"ORDER BY veces DESC, palabra ASC \"\n",
    "    return graph.run(query).to_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lista_palabras_mas_dichas_hist(grupo, plenos):\n",
    "    query = \"MATCH (d:Diputado)-[rel]-(p:Palabra) \"\n",
    "    query = query + \"WHERE d.grupo = '\" + grupo +\"' \"\n",
    "    query = query + \"AND rel.pleno IN \" + str(plenos) + \" \"\n",
    "    query = query + \"RETURN d.grupo as grupo, p.palabra as palabra, SUM(rel.veces) as veces \"\n",
    "    query = query + \"ORDER BY veces DESC, palabra ASC LIMIT 15\"\n",
    "    return graph.run(query).to_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historico = []\n",
    "graficos = []\n",
    "grafico_hist = []\n",
    "for ix, sesion in sesiones.iterrows():\n",
    "    historico.append(sesion['sesion'])\n",
    "    print(sesion['sesion'])\n",
    "    ses = []\n",
    "    ses_hist = []\n",
    "    for gr in grupos_parlamentarios:\n",
    "        palabras_mas_dichas = lista_palabras(gr, [sesion['sesion']])\n",
    "        if palabras_mas_dichas.empty:\n",
    "            palabras_mas_dichas = pd.DataFrame.from_dict({'pleno': [sesion['sesion']],\n",
    "                                                          'grupo': [gr],\n",
    "                                                          'palabra' : ['gobierno'],\n",
    "                                                          'veces' : [0]\n",
    "                                                         })\n",
    "            \n",
    "        palabras_mas_dichas_hist = lista_palabras_hist(gr, historico)   \n",
    "        \n",
    "        if palabras_mas_dichas_hist.empty:\n",
    "            palabras_mas_dichas_hist = pd.DataFrame.from_dict({'pleno': [sesion['sesion']],\n",
    "                                                               'grupo': [gr],\n",
    "                                                               'palabra' : ['gobierno'],\n",
    "                                                               'veces' : [0]\n",
    "                                                              })\n",
    "            \n",
    "        df = palabras_mas_dichas.merge(palabras_mas_dichas_hist,\n",
    "                                       how='left', left_on=['grupo', 'palabra'], right_on=['grupo','palabra']\n",
    "                                      ).rename(columns={'veces_x':'numero_veces', 'veces_y': 'veces_acumuladas'})\n",
    "\n",
    "        ses.append(df)\n",
    "        ses_hist.append(lista_palabras_mas_dichas_hist(gr, historico))\n",
    "\n",
    "    graficos.append([sesion['sesion'], ses])\n",
    "    grafico_hist.append([sesion['sesion'], ses_hist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for ind1, grafico_presente in enumerate(graficos):\n",
    "    for ind2, grupo in enumerate(grafico_presente[1]):\n",
    "        #cargamos debate, grupo, df palabras mas dichas, df, acumuladas, df totales para poder procesar despues\n",
    "        output.append([grupo['pleno'][0], \n",
    "                       grupo['grupo'][0], \n",
    "                       grupo[['palabra', 'numero_veces']], \n",
    "                       grupo[['palabra','veces_acumuladas']], \n",
    "                       grafico_hist[ind1][1][ind2][['palabra', 'veces']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('debate.pickle', 'wb') as handle:\n",
    "    pickle.dump(pd.DataFrame(output, columns =['debate', \n",
    "                                               'grupo', \n",
    "                                               'palabras_mas_dichas', \n",
    "                                               'palabras_acumuladas',\n",
    "                                               'palabras_mas_dichas_hist']).sort_values(by=['grupo', \n",
    "                                                                                            'debate']), \n",
    "                handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
