{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neo4j_connector as nc\n",
    "import re\n",
    "import docx\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tag import StanfordPOSTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dialogs(doc):\n",
    "    inicio = False\n",
    "    dialog = ''\n",
    "    dialogs = []\n",
    "    for par in doc.paragraphs:   \n",
    "        if par.text == '###':\n",
    "            inicio = True\n",
    "        else:\n",
    "            inicio = False\n",
    "\n",
    "        if inicio:\n",
    "            if dialog == '':\n",
    "                pass\n",
    "            else:\n",
    "                dialogs.append(dialog)\n",
    "            dialog = ''\n",
    "        else:\n",
    "            dialog = dialog + par.text + ' '\n",
    "    return dialogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_dialogs(dialogs):\n",
    "    output = []\n",
    "    for dialog in dialogs:\n",
    "        pos_fin = dialog.find(':')\n",
    "        output.append([dialog[:pos_fin].lower(), dialog[pos_fin + 1 :].lower()])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_parenthesis(text):\n",
    "    regex = r\" \\(([^\\)]+)\\)\"\n",
    "    matches = re.finditer(regex, text)\n",
    "    output = text\n",
    "    for matchNum, match in enumerate(matches, start=1):\n",
    "        t_parentesis = match.group()\n",
    "        output = output.replace(t_parentesis, '')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aunque no te lo creas a veces no se escribe del todo correctamente\n",
    "def clean_mr_mrs(text):\n",
    "    return text.replace('el señor ', '').replace('la señora ', '') \\\n",
    ".replace('el señora', '').replace('la señor', '') \\\n",
    ".replace('señor ', '').replace('señora ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    return text.replace('?', '').replace('¿', '').replace('«', '').replace('»', '') \\\n",
    ".replace('.', ' ').replace(',', ' ').replace('—', ' ').replace('-', ' ').replace('%', ' ') \\\n",
    ".replace('š', ' ').replace(';', ' ').replace('!', ' ').replace('¡', ' ') \\\n",
    ".replace('–', ' ').replace(' : ', ': ').replace(':', ' ').replace('…', ' ').replace('  ', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_names(name):\n",
    "    return name.replace('presidente del gobierno en funciones', 'sánchez pérez-castejón') \\\n",
    "        .replace('ministra de justicia en funciones', 'delgado garcía') \\\n",
    "        .replace('ministra de hacienda en funciones', 'montero cuadrado') \\\n",
    "        .replace('ministro del interior en funciones', 'grande-marlaska gómez') \\\n",
    "        .replace('rodrí guez hernández', 'rodríguez hernández') \\\n",
    "        .replace('ministro de agricultura pesca y alimentación en funciones', 'planas puchades') \\\n",
    "        .replace('ministro de fomento en funciones', 'ábalos meco') \\\n",
    "        .replace('ministra de economía y empresa en funciones', 'calviño santamaría') \\\n",
    "        .replace(' candidato a la presidencia del gobierno', '') \\\n",
    "        .replace('ministro de inclusión  seguridad social y migraciones', 'escrivá belmonte') \\\n",
    "        .replace('ministra de política territorial y función pública', 'darias san sebastián') \\\n",
    "        .replace('ministra de hacienda', 'montero cuadrado') \\\n",
    "        .replace('representante de la asamblea regional de murcia', 'conesa alcaraz') \\\n",
    "        .replace('de olano vela', 'olano vela') \\\n",
    "        .replace('ministro del interior', 'grande-marlaska gómez') \\\n",
    "        .replace('ministro de interior', 'grande-marlaska gómez') \\\n",
    "        .replace('ministro de agricultura pesca y alimentación', 'planas puchades') \\\n",
    "        .replace('ministro de transportes movilidad y agenda urbana', 'ábalos meco') \\\n",
    "        .replace('presidente del gobierno', 'sánchez pérez-castejón') \\\n",
    "        .replace('ministro de sanidad', 'illa roca') \\\n",
    "        .replace('concicao', 'garriga vaz de concicao') \\\n",
    "        .replace('oblanca', 'martínez oblanca') \\\n",
    "        .replace('ministra de igualdad', 'montero gil') \\\n",
    "        .replace('herrer', 'rodríguez herrer') \\\n",
    "        .replace('ministra de industria comercio y turismo', 'maroto illera') \\\n",
    "        .replace('ministro de inclusión seguridad social y migraciones', 'escrivá belmonte') \\\n",
    "        .replace(' moro', 'oramas gonzález-moro') \\\n",
    "        .replace('ministra de asuntos exteriores unión europea y cooperación', 'gonzález laya') \\\n",
    "        .replace('ministro de justicia', 'campo moreno') \\\n",
    "        .replace('vicepresidente segundo del gobierno y ministro de derechos sociales y agenda 2030', 'iglesias turrión') \\\n",
    "        .replace('martínez martínez oblanca', 'martínez oblanca') \\\n",
    "        .replace('sanchez', 'sánchez').replace('castejon', 'castejón') \\\n",
    "        .replace('ministro de inclusión, seguridad social y migraciones', 'escrivá belmonte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(dialog):\n",
    "    list_specific_stop_words = ['gracias', 'señor', 'señora', 'señorías', 'presidenta', 'ministro', 'ustedes',\n",
    "                                'usted', 'si', ]\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "\n",
    "    word_tokens = word_tokenize(dialog)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    filtered_sentence = [w for w in filtered_sentence if not w in list_specific_stop_words]\n",
    "        \n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dialogs(dialogs):\n",
    "    output = []\n",
    "    for dialog in dialogs:\n",
    "        speaker = clean_names(clean_mr_mrs(clean_parenthesis(dialog[0])))\n",
    "        text = remove_stopwords(clean_text(clean_parenthesis(dialog[1])))\n",
    "        output.append([speaker, text])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacenamos en una lista, la relacion y la lista de diálogos\n",
    "congreso = []\n",
    "for file in os.listdir('files/'):\n",
    "    if file[-4:] == 'docx':\n",
    "        doc = docx.Document('files/' + file) \n",
    "        dialogs = extract_dialogs(doc)\n",
    "        sep_dialogs = separate_dialogs(dialogs)\n",
    "        cl_dialogs = clean_dialogs(sep_dialogs)\n",
    "        relation = file[:-5]\n",
    "        congreso.append([relation, cl_dialogs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En este momento tenemos una estructura de este tipo:\n",
    "['ID_DEBATE', [[DIPUTADO, [PALABRAS]]]]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tagger_model(list_words, sw_generate_model):\n",
    "    jar = 'nlp/stanford-postagger.jar'\n",
    "    model = 'nlp/spanish.tagger'\n",
    "    nlp = spacy.load('es_core_news_md')\n",
    "    pos_tagger = StanfordPOSTagger(model, jar, encoding='utf8')\n",
    "    \n",
    "    if sw_generate_model:\n",
    "        print('GENERANDO MODELO')\n",
    "        try:\n",
    "            os.remove('words.pickle')\n",
    "        except:\n",
    "            pass\n",
    "        # taggeamos las palabras de 500 en 500 para no desbordar la memoria\n",
    "        salto = 500\n",
    "        dialog = list(set(list_words)) \n",
    "        a = len(dialog)\n",
    "        b = 0\n",
    "        print(a)\n",
    "        while b < a:\n",
    "            try:\n",
    "                with open('words.pickle', 'rb') as handle:\n",
    "                    words = pickle.load(handle)\n",
    "                    words.extend(pos_tagger.tag(dialog[b:b + salto]))\n",
    "                    with open('words.pickle', 'wb') as handle:\n",
    "                        pickle.dump(words, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            except:\n",
    "                print(\"CREAMOS NUEVO MODELO\")\n",
    "                words = pos_tagger.tag(dialog[b:b + salto])\n",
    "\n",
    "                with open('words.pickle', 'wb') as handle:\n",
    "                    pickle.dump(words, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "            b = b + salto - 1\n",
    "    else:\n",
    "        print(\"CARGAMOS MODELO\")\n",
    "        with open('words.pickle', 'rb') as handle:\n",
    "            words = pickle.load(handle)\n",
    "             \n",
    "    print(\"MODELO TERMINADO\")\n",
    "\n",
    "    output = []\n",
    "    for word in words:\n",
    "        if word[0].isnumeric():\n",
    "            pass\n",
    "        else:\n",
    "            temp = nlp(word[0])[0].lemma_\n",
    "            if word[1][0:2] in ['nc', 'np', 'aq']:\n",
    "                if temp not in ['así', 'parte', 'puede', 'hace', 'hacer', 'diputado', 'diputados', '%']:\n",
    "                    output.append(temp)\n",
    "            else:\n",
    "                if word[1][0:1] == 'v':\n",
    "                    if temp not in ['ser', 'hacer', 'ir', 'decir', 'poder', 'estar', \n",
    "                                    'llevar', 'tener', 'querer', 'ser']:\n",
    "                        output.append(temp)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_list_words(congreso):\n",
    "    output = []\n",
    "    for el1 in congreso:\n",
    "        for el2 in el1[1]:\n",
    "            output.extend(el2[1])  \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_words = generate_list_words(congreso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tagger_model = generate_tagger_model(list_words, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dialogs (congreso, list_words_tagged):\n",
    "    print('INCIO CARGA DIALOGOS')\n",
    "    nlp = spacy.load('es_core_news_md')\n",
    "    graph = nc.generate_graph()\n",
    "    matcher = nc.generate_nodeMatcher(graph)\n",
    "    print('DOCUMENTOS ' + str(len(congreso)))\n",
    "    for el1 in congreso:\n",
    "        relation = el1[0]\n",
    "        print('DIALOGOS ' + str(len(el1[1])))\n",
    "        for el2 in el1[1]:\n",
    "            speaker = el2[0].strip()\n",
    "            diputado = nc.return_diputado(matcher, speaker)\n",
    "            if diputado is None:\n",
    "                print(\"PERSONA NO ENCONTRADA: \")\n",
    "                print(speaker)\n",
    "                print(relation)\n",
    "            else:\n",
    "                for word in el2[1]:\n",
    "                    lemma = nlp(word)[0].lemma_\n",
    "                    if lemma in list_words_tagged:\n",
    "                        graph.run(nc.insert_palabra(word))\n",
    "                        graph.run(nc.insert_relation(diputado['apellidos'], word, relation))\n",
    "                    else:\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dialogs(congreso, tagger_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
